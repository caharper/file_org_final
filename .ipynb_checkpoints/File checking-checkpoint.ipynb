{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is based on the idea that users can initialize the database with 3 files (a routes file, a driver file, and a driver assignment file).  However, once these files are loaded, the user cannot append to the data that we are storing through an additional csv file.  For example, if a user initialized the DB with ./routes_file_1, they cannot also append to the routes with a ./routes_file_2.  This is important for a number of reasons that I don't want to write out but we can talk about them if we want.  We could allow for a \"clear DB\" button and allow the user to re-initialize though.\n",
    "\n",
    "We probably want to refactor into using parquet files like here: https://stackoverflow.com/questions/61920105/dask-applying-a-function-over-a-large-dataframe-which-is-more-than-ram\n",
    "\n",
    "Not a huge change and the current code should pretty much work when we do that. Waiting to do this though because some of the operations that we need to check for depend on the whole dataframe and I'm still learning Dask. \n",
    "\n",
    "Some of the implementation could be done a lot more efficiently, but for now I left it this way explicitly so that it is clear how it operates.  We can adjust later.\n",
    "\n",
    "\n",
    "\n",
    "**Don't use dask.compute()  Puts everything in main memory!**\n",
    "\n",
    "**Use pip to install dask if you want to install yourself.  Had issues with conda**\n",
    "\n",
    "**I added a .yml file so that we can just use the same conda environment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use dask or sframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "n_cpus = multiprocessing.cpu_count()\n",
    "n_cpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import dask\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import glob\n",
    "from shutil import copyfile\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1440"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "24*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person():\n",
    "    def __init__(self):\n",
    "        # tuples with start time, finish time of busy blocks\n",
    "        self.day_busy_times = []\n",
    "        days = ['M', 'T', 'W', 'U', 'F', 'S', 's']\n",
    "        self.day_to_int = {day: i for i, day in enumerate(days)}\n",
    "        self.day_to_day_start_min = {day: 24*i*60 for i, day in enumerate(days)}\n",
    "        print(self.day_to_day_start_min)\n",
    "        \n",
    "        self.home_city, self.home_state = '', ''\n",
    "        \n",
    "    def _get_drive_and_break(self, start_day, start_hr, start_min, drive_hr, drive_min):\n",
    "        \n",
    "        # cast all to ints\n",
    "        start_hr, start_min = int(start_hr), int(start_min)\n",
    "        drive_hr, drive_min = int(drive_hr), int(drive_min)\n",
    "        \n",
    "        drive_time_in_mins = 60*drive_hr + drive_min\n",
    "        break_in_mins = math.ceil(drive_time_in_mins/2) # add 18hr check later\n",
    "        busy_time_in_mins = drive_time_in_mins + break_in_mins\n",
    "        \n",
    "        start_time = self.day_to_day_start_min[start_day] + 60*start_hr + start_min\n",
    "        end_time = (start_time + busy_time_in_mins)%(24*60)\n",
    "        \n",
    "        return start_time, end_time\n",
    "    \n",
    "    def _check_busy(self, start_day, start_hr, start_min, drive_hr, drive_min):\n",
    "        \n",
    "        # get the time block that we want to allocate for the drive and break\n",
    "        start_time, end_time = self._get_drive_and_break(self, start_day, start_hr, \n",
    "                                                         start_min, drive_hr, drive_min)\n",
    "        \n",
    "        # Check if there is overlap with times\n",
    "        for busy_start, busy_end in self.day_busy_times:\n",
    "            \n",
    "            # if start drive in the middle of a busy block\n",
    "            if busy_start <= start_time <= busy_end:\n",
    "                busy = True\n",
    "                break\n",
    "                    \n",
    "            # if end of break is in the middle of a busy block\n",
    "            if busy_start <= end_time <= busy_end:\n",
    "                busy = True\n",
    "                    break\n",
    "                    \n",
    "            # if the end time is the following week \n",
    "            if start_time > end_time:\n",
    "                '''*****************'''\n",
    "    \n",
    "    \n",
    "    \n",
    "    def is_availiable(self, start_day, start_hr, start_min, drive_hr, drive_min, dest_city, dest_state,\n",
    "                     src_city, src_state):\n",
    "        \n",
    "        # check if the drive overlaps with any busy blocks\n",
    "        overlap_busy = self._check_busy(self, start_day, start_hr, start_min, drive_hr, drive_min)\n",
    "        \n",
    "        \n",
    "    def add_busy_time(self, start_day, start_hr, start_min, drive_hr, drive_min):\n",
    "        ''' Adds a datetime tuple (start time and end time) to day_busy_times\n",
    "            Note: automatically adds in break times.\n",
    "            \n",
    "            Assumes that is_busy has returned False\n",
    "        '''\n",
    "        \n",
    "        # get the time block that we want to allocate for the drive and break\n",
    "        start_time, end_time = self._get_drive_and_break(self, start_day, start_hr, \n",
    "                                                         start_min, drive_hr, drive_min)\n",
    "            \n",
    "        self.day_busy_times.append((start_time, end_time))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "    def is_busy(self, start_day, start_hr, start_min):\n",
    "        \n",
    "        # cast all to ints\n",
    "        start_hr, start_min = int(start_hr), int(start_min)\n",
    "\n",
    "        start_time = self.day_to_day_start_min[start_day] + 60*start_hr + start_min\n",
    " \n",
    "        busy = False\n",
    "        \n",
    "        # Check if there is overlap with times\n",
    "        for busy_start, busy_end in self.day_busy_times:\n",
    "            # since days could carry on to the next week,\n",
    "            # if the start time is in a busy block\n",
    "            if busy_start <= start_time <= busy_end:\n",
    "                busy = True\n",
    "                break\n",
    "                \n",
    "            # if overlaped on weekend, must check all days\n",
    "            if busy\n",
    "            \n",
    "            \n",
    "            \n",
    "            # since days could carry on to the next week, make sure to take the min of start end \n",
    "            if busy_start > busy_end: \n",
    "                busy_start, busy_end = busy_end, busy_start\n",
    "                print(busy_start, busy_end)\n",
    "            if start_time >= busy_start and start_time <= busy_end:\n",
    "                busy = True\n",
    "                break\n",
    "                \n",
    "        return busy\n",
    "        \n",
    "    def add_busy_time(self, start_day, start_hr, start_min, drive_hr, drive_min):\n",
    "        ''' Adds a datetime tuple (start time and end time) to day_busy_times\n",
    "            Note: automatically adds in break times.\n",
    "            \n",
    "            Assumes that is_busy has returned False\n",
    "        '''\n",
    "        \n",
    "        # cast all to ints\n",
    "        start_hr, start_min = int(start_hr), int(start_min)\n",
    "        drive_hr, drive_min = int(drive_hr), int(drive_min)\n",
    "        \n",
    "        drive_time_in_mins = 60*drive_hr + drive_min\n",
    "        break_in_mins = math.ceil(drive_time_in_mins/2)\n",
    "        busy_time_in_mins = drive_time_in_mins + break_in_mins\n",
    "        \n",
    "#         busy_hr = busy_time_in_mins//60\n",
    "#         busy_min = busy_time_in_mins%60\n",
    "        \n",
    "        start_time = self.day_to_day_start_min[start_day] + 60*start_hr + start_min\n",
    "        end_time = (start_time + busy_time_in_mins)%(24*60)\n",
    "            \n",
    "        self.day_busy_times.append((start_time, end_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'M': 0, 'T': 1440, 'W': 2880, 'U': 4320, 'F': 5760, 'S': 7200, 's': 8640}\n",
      "[(8640, 720)]\n"
     ]
    }
   ],
   "source": [
    "p = Person()\n",
    "\n",
    "tup_1_ = ('s')\n",
    "# day, timehr, timemin\n",
    "tup_1_start = ('s', '00', '00')\n",
    "# durhr, dur min\n",
    "tup_1_duration = ('24', '00')\n",
    "\n",
    "if not p.is_busy(tup_1_start[0], tup_1_start[1], tup_1_start[2]):\n",
    "    p.add_busy_time(tup_1_start[0], tup_1_start[1], tup_1_start[2], tup_1_duration[0], tup_1_duration[1])\n",
    "    print(p.day_busy_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720 8640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# day, timehr, timemin\n",
    "tup_2_start = ('W', '12', '00')\n",
    "# durhr, dur min\n",
    "tup_2_duration = ('10', '30')\n",
    "\n",
    "p.is_busy(tup_2_start[0], tup_2_start[1], tup_2_start[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Person():\n",
    "#     def __init__(self):\n",
    "#         # Key: day Value: list tuples of busy time blocks\n",
    "#         self.day_busy_times = []\n",
    "#         days = ['M', 'T', 'W', 'U', 'F', 'S', 's']\n",
    "#         self.day_to_int = {day: i+1 for i, day in enumerate(days)}\n",
    "#         print(self.day_to_int)\n",
    "        \n",
    "#     def is_busy(self, start_day, start_hr, start_min):\n",
    "#         # cast all to ints\n",
    "#         start_hr, start_min = int(start_hr), int(start_min)\n",
    "# #         drive_hr, drive_min = int(drive_hr), int(drive_min)\n",
    "        \n",
    "#         start_day = datetime(year=2020, month=1, day=self.day_to_int[start_day], hour=start_hr, minute=start_min)\n",
    "# #         end_time = start_day + timedelta(hours=drive_hr, minutes=drive_min)\n",
    "        \n",
    "#         busy = False\n",
    "        \n",
    "#         # Check if there is overlap with times\n",
    "#         for busy_start, busy_end in self.day_busy_times:\n",
    "#             if start_day >= busy_start and start_day <= busy_end:\n",
    "#                 busy = True\n",
    "#                 break\n",
    "                \n",
    "#         return busy\n",
    "        \n",
    "#     def add_busy_time(self, start_day, start_hr, start_min, drive_hr, drive_min):\n",
    "#         ''' Adds a datetime tuple (start time and end time) to day_busy_times\n",
    "#             Note: automatically adds in break times.\n",
    "            \n",
    "#             Assumes that is_busy has returned False\n",
    "#         '''\n",
    "        \n",
    "#         # cast all to ints\n",
    "#         start_hr, start_min = int(start_hr), int(start_min)\n",
    "#         drive_hr, drive_min = int(drive_hr), int(drive_min)\n",
    "        \n",
    "#         drive_time_in_mins = 60*drive_hr + drive_min\n",
    "#         break_in_mins = math.ceil(drive_time_in_mins/2)\n",
    "#         busy_time_in_mins = drive_time_in_mins + break_in_mins\n",
    "        \n",
    "#         busy_hr = busy_time_in_mins//60\n",
    "#         busy_min = busy_time_in_mins%60\n",
    "    \n",
    "#         start_day = datetime(year=2020, month=1, day=self.day_to_int[start_day],\n",
    "#                              hour=int(start_hr), minute=int(start_min))\n",
    "#         end_time = start_day + timedelta(hours=busy_hr, minutes=busy_min)\n",
    "\n",
    "#         # Wrap around to monday (for example) so saturday overnight drives continue to the following monday\n",
    "#         if end_time.day > 7:\n",
    "            \n",
    "#             # duplicate schedule for second week for overlap\n",
    "            \n",
    "            \n",
    "# #             end_day_wrapped = end_time.day%7\n",
    "            \n",
    "# #             # datetime.date objects are not writable, so replace value with their helper\n",
    "# #             end_time = end_time.replace(day=end_time.day%7)\n",
    "            \n",
    "# #             # make sure to include busy time since wrapped around\n",
    "# #             for driving_days in range(1, (end_time.day%7)+1):\n",
    "                \n",
    "# #                 # if at the last wrapped day\n",
    "# #                 if end_day_wrapped == driving_days:\n",
    "                \n",
    "# #                 else:\n",
    "# #                     # block off the whole day\n",
    "# #                     self.day_busy_times.append((start_day, end_time))\n",
    "            \n",
    "#         self.day_busy_times.append((start_day, end_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "('h', 6) is ('h',6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person():\n",
    "    '''Works!\n",
    "    \n",
    "    \n",
    "    Need to add in things to check if in home city for rest time adjustment\n",
    "    '''\n",
    "    def __init__(self, home_city, home_state):\n",
    "        # Key: day Value: list tuples of busy time blocks\n",
    "        self.day_busy_times = []\n",
    "        days = ['M', 'T', 'W', 'U', 'F', 'S', 's']\n",
    "        self.day_to_int = {day: i+1 for i, day in enumerate(days)}\n",
    "        print(self.day_to_int)\n",
    "        self.home_city = home_city\n",
    "        self.home_state = home_state\n",
    "             \n",
    "    def is_availiable(self, start_day, start_hr, start_min, drive_hr, drive_min):\n",
    "        '''Checks if the time is availiable and the source city is able to be reached\n",
    "        \n",
    "        For the source city, it is availiable to be reached if the following conditions are met:\n",
    "        \n",
    "            1. Source is the home city \n",
    "        '''\n",
    "        # cast all to ints\n",
    "        start_hr, start_min = int(start_hr), int(start_min)\n",
    "#         drive_hr, drive_min = int(drive_hr), int(drive_min)\n",
    "        \n",
    "        start_day = datetime(year=2020, month=1, day=self.day_to_int[start_day], hour=start_hr, minute=start_min)\n",
    "#         end_time = start_day + timedelta(hours=drive_hr, minutes=drive_min)\n",
    "        \n",
    "        busy = False\n",
    "        \n",
    "        # Check if there is overlap with times\n",
    "        for _, busy_start, busy_end in self.day_busy_times:\n",
    "            if start_day >= busy_start and start_day <= busy_end: # verify that I only need to check the start time\n",
    "                '''\n",
    "                    do I need to check if the break time of the assignment could get in the way?\n",
    "                    \n",
    "                    Like say I have a block on monday from 12-4 blocked off but then I want to see \n",
    "                    if I can assign a 2hr drive from 10-12.  This logic currently would say availible\n",
    "                    because 10am start is not between 12 and 4 but the break would cause an issue.  Fix\n",
    "                    this logic.\n",
    "                '''\n",
    "                busy = True\n",
    "                break\n",
    "                \n",
    "        return busy\n",
    "        \n",
    "    def add_busy_time(self, start_day, start_hr, start_min, drive_hr, drive_min, dest_city, dest_state):\n",
    "        ''' Adds a datetime tuple (start time and end time) to day_busy_times\n",
    "            Note: automatically adds in break times.\n",
    "            \n",
    "            Assumes that is_busy has returned False\n",
    "        '''\n",
    "        \n",
    "        # cast all to ints\n",
    "        start_hr, start_min = int(start_hr), int(start_min)\n",
    "        drive_hr, drive_min = int(drive_hr), int(drive_min)\n",
    "        \n",
    "        drive_time_in_mins = 60*drive_hr + drive_min\n",
    "        \n",
    "        break_in_mins = math.ceil(drive_time_in_mins/2)\n",
    "        \n",
    "        # If home city, take the max of drive_time/2 and 18hr\n",
    "        if (home_city, home_state) == (dest_city, dest_state):\n",
    "            break_in_mins = max(break_in_mins, 18*60)\n",
    "        \n",
    "        busy_time_in_mins = drive_time_in_mins + break_in_mins\n",
    "        \n",
    "        busy_hr = busy_time_in_mins//60\n",
    "        busy_min = busy_time_in_mins%60\n",
    "    \n",
    "        start_time = datetime(year=2020, month=1, day=self.day_to_int[start_day],\n",
    "                             hour=int(start_hr), minute=int(start_min))\n",
    "        end_time = start_time + timedelta(hours=busy_hr, minutes=busy_min)\n",
    "        print(f'End time: {end_time}')\n",
    "\n",
    "        # Wrap around to monday (for example) so saturday overnight drives \n",
    "        # continue to the following monday\n",
    "        if end_time.day > 7:\n",
    "    \n",
    "            # From start time to end of day\n",
    "            end_first_day = datetime(year=2020, month=1, day=start_time.day, \n",
    "                                     hour=23, minute=59)\n",
    "            self.day_busy_times.append((start_time, end_first_day))\n",
    "            \n",
    "            # Overlap will start at the beginning of the day\n",
    "            over_weekend_day = datetime(year=2020, month=1, day=self.day_to_int[start_day],\n",
    "                             hour=0, minute=0)\n",
    "            \n",
    "            # Last overlap day \n",
    "            last_day_wrapped = end_time.day%7\n",
    "\n",
    "            # make sure to include busy time since wrapped around (and can only go for 72 hours)\n",
    "            for driving_days in range(1, last_day_wrapped+1):\n",
    "                \n",
    "                over_weekend_day = over_weekend_day.replace(day=driving_days%7)\n",
    "                \n",
    "                # if at the last wrapped day\n",
    "                if last_day_wrapped == driving_days:\n",
    "                    end_time = end_time.replace(day=last_day_wrapped)\n",
    "                    self.day_busy_times.append((over_weekend_day, end_time))\n",
    "                \n",
    "                else:\n",
    "                    # block off the whole day\n",
    "                    last_minute_of_day = datetime(year=2020, month=1, day=driving_days,\n",
    "                             hour=23, minute=59)\n",
    "                    self.day_busy_times.append((over_weekend_day, last_minute_of_day))\n",
    "                    \n",
    "        else:\n",
    "            self.day_busy_times.append((start_time, end_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person():\n",
    "    '''Works!\n",
    "    \n",
    "    \n",
    "    Need to add in things to check if in home city for rest time adjustment\n",
    "    '''\n",
    "    def __init__(self, home_city, home_state):\n",
    "        # Key: day Value: list tuples of busy time blocks\n",
    "        self.day_busy_times = []\n",
    "        days = ['M', 'T', 'W', 'U', 'F', 'S', 's']\n",
    "        self.day_to_int = {day: i+1 for i, day in enumerate(days)}\n",
    "        print(self.day_to_int)\n",
    "        self.home_city = home_city\n",
    "        self.home_state = home_state\n",
    "        \n",
    "    def is_availiable(self, start_day, start_hr, start_min, drive_hr, drive_min, \n",
    "                      src_city, src_state, dest_city, dest_state):\n",
    "        \n",
    "        # check if the source city is reachable (48 hours or connections)\n",
    "        is_reachable, busy_blocks = self._city_is_reachable(self, start_day, start_hr, \n",
    "                                                            start_min, drive_hr, drive_min, \n",
    "                                                            src_city, src_state, dest_city,\n",
    "                                                            dest_state)\n",
    "        \n",
    "\n",
    "        # check if there is overlap with busy slots in schedule\n",
    "        \n",
    "        # return True/False and the busy blocks to add for traveling to src (if applicable)\n",
    "        \n",
    "    def _make_route_time_block()\n",
    "        \n",
    "    \n",
    "    def _city_is_reachable(self, start_day, start_hr, start_min, drive_hr, drive_min, \n",
    "                      src_city, src_state, dest_city, dest_state):\n",
    "        \n",
    "        '''\n",
    "            Returns:\n",
    "            \n",
    "            True, [busy_time_blocks]\n",
    "                busy_time_blocks for traveling to the src city\n",
    "            False, []\n",
    "        '''\n",
    "        \n",
    "        # check if previous city and next city are issues\n",
    "        \n",
    "        # sort time objects to get previous city and next city\n",
    "        sorted_busy_times = sorted(self.day_busy_times)\n",
    "        \n",
    "        \n",
    "        \n",
    "        '''\n",
    "        possible issue here if not checking next city\n",
    "        \n",
    "            what if I just check the previous city.  Say currently I get into\n",
    "            Chicago at 8am Monday.  I want to insert Chicago to NYC on 8am Tues.\n",
    "            That insert is granted b/c source city.\n",
    "            \n",
    "            What if now I want to insert 12pm Monday Chicago to Dallas.  That would\n",
    "            be granted if I didn't check the next city so must check the next city. \n",
    "            Otherwise this would've put the driver in Dallas when they need to go from\n",
    "            Chicago to NYC.\n",
    "            \n",
    "            The other issue now is say Chicago to NYC is on 8am Friday. I need to check \n",
    "            that Chicago to Dallas leaves me either 48hr to get back to Chicago for the\n",
    "            Friday trip or if routes can get me back to Chicago.  \n",
    "            \n",
    "            Connections could cause issues later as well.  Say routes were able to take\n",
    "            me back to Chicago--that tuple would be inserted.  Now if we wanted to insert\n",
    "            a new tuple and saw that we could fit a trip in from Dallas to Houston, we need\n",
    "            to check if that person is taking buses during this time.  We need to add these \n",
    "            to the busy times.\n",
    "        '''\n",
    "        \n",
    "        # check if 48 hours to get there \n",
    "        \n",
    "    def _check_48hr(self):\n",
    "        return False\n",
    "        \n",
    "        \n",
    "        \n",
    "    def is_availiable(self, start_day, start_hr, start_min, drive_hr, drive_min):\n",
    "        '''Checks if the time is availiable and the source city is able to be reached\n",
    "        \n",
    "        For the source city, it is availiable to be reached if the following conditions are met:\n",
    "        \n",
    "            1. Source is the home city \n",
    "        '''\n",
    "        # cast all to ints\n",
    "        start_hr, start_min = int(start_hr), int(start_min)\n",
    "#         drive_hr, drive_min = int(drive_hr), int(drive_min)\n",
    "        \n",
    "        start_day = datetime(year=2020, month=1, day=self.day_to_int[start_day], hour=start_hr, minute=start_min)\n",
    "#         end_time = start_day + timedelta(hours=drive_hr, minutes=drive_min)\n",
    "        \n",
    "        busy = False\n",
    "        \n",
    "        # Check if there is overlap with times\n",
    "        for _, busy_start, busy_end in self.day_busy_times:\n",
    "            if start_day >= busy_start and start_day <= busy_end: # verify that I only need to check the start time\n",
    "                '''\n",
    "                    do I need to check if the break time of the assignment could get in the way?\n",
    "                    \n",
    "                    Like say I have a block on monday from 12-4 blocked off but then I want to see \n",
    "                    if I can assign a 2hr drive from 10-12.  This logic currently would say availible\n",
    "                    because 10am start is not between 12 and 4 but the break would cause an issue.  Fix\n",
    "                    this logic.\n",
    "                '''\n",
    "                busy = True\n",
    "                break\n",
    "                \n",
    "        return busy\n",
    "        \n",
    "    def add_busy_time(self, start_day, start_hr, start_min, drive_hr, drive_min, dest_city, dest_state):\n",
    "        ''' Adds a datetime tuple (start time and end time) to day_busy_times\n",
    "            Note: automatically adds in break times.\n",
    "            \n",
    "            Assumes that is_busy has returned False\n",
    "        '''\n",
    "        \n",
    "        # cast all to ints\n",
    "        start_hr, start_min = int(start_hr), int(start_min)\n",
    "        drive_hr, drive_min = int(drive_hr), int(drive_min)\n",
    "        \n",
    "        drive_time_in_mins = 60*drive_hr + drive_min\n",
    "        \n",
    "        break_in_mins = math.ceil(drive_time_in_mins/2)\n",
    "        \n",
    "        # If home city, take the max of drive_time/2 and 18hr\n",
    "        if (home_city, home_state) == (dest_city, dest_state):\n",
    "            break_in_mins = max(break_in_mins, 18*60)\n",
    "        \n",
    "        busy_time_in_mins = drive_time_in_mins + break_in_mins\n",
    "        \n",
    "        busy_hr = busy_time_in_mins//60\n",
    "        busy_min = busy_time_in_mins%60\n",
    "    \n",
    "        start_time = datetime(year=2020, month=1, day=self.day_to_int[start_day],\n",
    "                             hour=int(start_hr), minute=int(start_min))\n",
    "        end_time = start_time + timedelta(hours=busy_hr, minutes=busy_min)\n",
    "        print(f'End time: {end_time}')\n",
    "\n",
    "        # Wrap around to monday (for example) so saturday overnight drives \n",
    "        # continue to the following monday\n",
    "        if end_time.day > 7:\n",
    "    \n",
    "            # From start time to end of day\n",
    "            end_first_day = datetime(year=2020, month=1, day=start_time.day, \n",
    "                                     hour=23, minute=59)\n",
    "            self.day_busy_times.append((start_time, end_first_day))\n",
    "            \n",
    "            # Overlap will start at the beginning of the day\n",
    "            over_weekend_day = datetime(year=2020, month=1, day=self.day_to_int[start_day],\n",
    "                             hour=0, minute=0)\n",
    "            \n",
    "            # Last overlap day \n",
    "            last_day_wrapped = end_time.day%7\n",
    "\n",
    "            # make sure to include busy time since wrapped around (and can only go for 72 hours)\n",
    "            for driving_days in range(1, last_day_wrapped+1):\n",
    "                \n",
    "                over_weekend_day = over_weekend_day.replace(day=driving_days%7)\n",
    "                \n",
    "                # if at the last wrapped day\n",
    "                if last_day_wrapped == driving_days:\n",
    "                    end_time = end_time.replace(day=last_day_wrapped)\n",
    "                    self.day_busy_times.append((over_weekend_day, end_time))\n",
    "                \n",
    "                else:\n",
    "                    # block off the whole day\n",
    "                    last_minute_of_day = datetime(year=2020, month=1, day=driving_days,\n",
    "                             hour=23, minute=59)\n",
    "                    self.day_busy_times.append((over_weekend_day, last_minute_of_day))\n",
    "                    \n",
    "        else:\n",
    "            self.day_busy_times.append((start_time, end_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'M': 1, 'T': 2, 'W': 3, 'U': 4, 'F': 5, 'S': 6, 's': 7}\n",
      "End time: 2020-01-08 12:00:00\n",
      "[(datetime.datetime(2020, 1, 7, 0, 0), datetime.datetime(2020, 1, 7, 23, 59)), (datetime.datetime(2020, 1, 1, 0, 0), datetime.datetime(2020, 1, 1, 12, 0))]\n"
     ]
    }
   ],
   "source": [
    "p = Person()\n",
    "\n",
    "tup_1_ = ('s')\n",
    "# day, timehr, timemin\n",
    "tup_1_start = ('s', '00', '00')\n",
    "# durhr, dur min\n",
    "tup_1_duration = ('24', '00')\n",
    "\n",
    "if not p.is_busy(tup_1_start[0], tup_1_start[1], tup_1_start[2]):\n",
    "    p.add_busy_time(tup_1_start[0], tup_1_start[1], tup_1_start[2], tup_1_duration[0], tup_1_duration[1])\n",
    "    print(p.day_busy_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# day, timehr, timemin\n",
    "tup_2_start = ('W', '12', '00')\n",
    "# durhr, dur min\n",
    "tup_2_duration = ('10', '30')\n",
    "\n",
    "p.is_busy(tup_2_start[0], tup_2_start[1], tup_2_start[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/clayharper/anaconda/envs/db_project_dask/lib/python3.7/site-packages/dask/dataframe/core.py:6194: UserWarning: Insufficient elements for `head`. 5 elements requested, only 1 elements available. Try passing larger `npartitions` to `head`.\n",
      "  warnings.warn(msg.format(n, len(r)))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_id</th>\n",
       "      <th>route_name</th>\n",
       "      <th>src_city_name</th>\n",
       "      <th>src_state_code</th>\n",
       "      <th>dest_city_name</th>\n",
       "      <th>dest_state_code</th>\n",
       "      <th>route_type</th>\n",
       "      <th>dep_time_hr</th>\n",
       "      <th>dep_time_min</th>\n",
       "      <th>travel_time_hr</th>\n",
       "      <th>travel_time_min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1345</td>\n",
       "      <td>None</td>\n",
       "      <td>Waco</td>\n",
       "      <td>TX</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>TX</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      route_id route_name src_city_name src_state_code dest_city_name  \\\n",
       "index                                                                   \n",
       "2        A1345       None          Waco             TX         Dallas   \n",
       "\n",
       "      dest_state_code route_type dep_time_hr dep_time_min travel_time_hr  \\\n",
       "index                                                                      \n",
       "2                  TX          0          20            0             72   \n",
       "\n",
       "      travel_time_min  \n",
       "index                  \n",
       "2                   0  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DaskReader():\n",
    "    ''' Base class for reading csv files with Dask.  \n",
    "\n",
    "    '''\n",
    "    def __init__(self, csv_path):\n",
    "        # Verify that the path extension is .csv\n",
    "        self._verify_csv_format(csv_path)\n",
    "        self.csv_path = csv_path\n",
    "        \n",
    "        self.state_codes = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\",\n",
    "                            \"DC\", \"DE\", \"FL\", \"GA\", \"HI\", \"ID\", \"IL\", \n",
    "                            \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \n",
    "                            \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\",\n",
    "                            \"NV\", \"NH\", \"NJ\", \"NM\", \"NY\", \"NC\", \"ND\",\n",
    "                            \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \"SD\", \n",
    "                            \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \n",
    "                            \"WI\", \"WY\"]\n",
    "        \n",
    "    def _verify_csv_format(self, file):\n",
    "        if Path(file).suffix == '.csv':\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def _is_nan(self, x):\n",
    "        if x != x or x is None:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def _verify_str_len(self, x, min_len, max_len):\n",
    "        if self._is_nan(x):\n",
    "            return False\n",
    "        \n",
    "        if len(x) < min_len or len(x) > max_len:\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def _verify_id(self, x):\n",
    "        if self._is_nan(x):\n",
    "            return False\n",
    "        \n",
    "        if not x.isalnum() or len(x) != 5:\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def _verify_int_value(self, x, min_x, max_x):\n",
    "        # make sure is an int\n",
    "        if not x.isdigit():\n",
    "            return False\n",
    "        \n",
    "        int_x = int(x)\n",
    "        if int_x < min_x or int_x > max_x:\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def _is_empty(self, df):\n",
    "        if len(df.index) == 0:\n",
    "            return True\n",
    "        return False\n",
    "                \n",
    "    def _read_df(self, file_type, names=None):\n",
    "        '''Get a dask dataframe from the file\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        names : list of str names for columns in a csv file.\n",
    "            This assumes that the correct amount of names is passed into this \n",
    "            function so that it matches up with the csv file. This also assumes\n",
    "            that the csv files do not have a header with column names initially.\n",
    "            By saving as a group of parquet files, we keep the operations from\n",
    "            causing memory issues.\n",
    "        '''\n",
    "        df = dd.read_csv(self.csv_path, header=None, dtype='str', names=names)\n",
    "        df.repartition(partition_size=\"100MB\")\n",
    "        \n",
    "        # save as parquet files\n",
    "        parquet_path = './parquet_processing/' + file_type + '/'\n",
    "        df.to_parquet(parquet_path)\n",
    "#         print(dd.read_parquet(parquet_path).head())\n",
    "        return dd.read_parquet(parquet_path)\n",
    "\n",
    "    def _concat_files(self, files, dest):\n",
    "            \n",
    "        # only append to avoid memory issues\n",
    "        with open(dest, 'a') as f:\n",
    "            for csvFile in files:\n",
    "                for line in open(csvFile, 'r'):\n",
    "                    f.write(line)\n",
    "    \n",
    "class AssignmentReader(DaskReader):\n",
    "    def __init__(self, csv_path):\n",
    "        super().__init__(csv_path)\n",
    "        \n",
    "        self.column_names = ['driver_id', 'route_id', 'day_of_week']\n",
    "        \n",
    "        self.valid_days = ['M', 'T', 'W', 'U', 'F', 'S', 's']\n",
    "        \n",
    "        self.df = self.read_df()\n",
    "        \n",
    "    def read_df(self):\n",
    "        return self._read_df(file_type='assignments', names=self.column_names)\n",
    "    \n",
    "    def verify_df(self):\n",
    "        self._verify_attributes()\n",
    "        \n",
    "    def _verify_times(self):\n",
    "        a = self.df.groupby(column_name)\n",
    "#         t = a.apply(self.checker, meta=pd.Series([], dtype='str', name='x'))\n",
    "        \n",
    "        t = a.apply(lambda x: self.test(x), meta=pd.Series([], dtype='str', name='x'))\n",
    "        \n",
    "        \n",
    "    def _verify_attributes(self):\n",
    "        '''Verifies basic attributes in the table. \n",
    "        \n",
    "        We verify that each of the attributes follows the datastructures we are placing on them.\n",
    "        Note: we must check if the dataframe is empty so that we avoid KeyErrors.\n",
    "        '''\n",
    "        \n",
    "        if self._is_empty(self.df):\n",
    "            return self.df\n",
    "        \n",
    "        # driver_id must be 5 characters and alphanumeric\n",
    "        self.df = self.df[self.df['driver_id'].apply(\n",
    "            lambda x: self._verify_id(x), meta=pd.Series([], dtype='str', name='x'))]\n",
    "        \n",
    "        if self._is_empty(self.df):\n",
    "            return self.df\n",
    "        \n",
    "        # route_ID must be 5 characters and alphanumeric\n",
    "        self.df = self.df[self.df['route_id'].apply(\n",
    "            lambda x: self._verify_id(x), meta=pd.Series([], dtype='str', name='x'))]\n",
    "\n",
    "        if self._is_empty(self.df):\n",
    "            return self.df\n",
    "\n",
    "        # day_of_week must be 1 characters and valid day of week\n",
    "        self.df = self.df[self.df['day_of_week'].apply(\n",
    "            lambda x: self._verify_str_len(x, 1, 1) and x in self.valid_days,\n",
    "            meta=pd.Series([], dtype='str', name='x'))]\n",
    "        \n",
    "        if self._is_empty(self.df):\n",
    "            return self.df\n",
    "        \n",
    "        # drop duplicates\n",
    "        self.df = self.df.reset_index().drop_duplicates(['driver_id', 'route_id', \n",
    "                                                         'day_of_week']).set_index(\"index\")\n",
    "    \n",
    "        \n",
    "class DriverReader(DaskReader):\n",
    "    ''' Reads driver csv files.\n",
    "    \n",
    "    Expected Columns\n",
    "    ----------------\n",
    "    driver_id (unique)\n",
    "    last_name\n",
    "    first_name\n",
    "    age (years)\n",
    "    home_city\n",
    "    home_state(standard US state code, 2 characters)\n",
    "    \n",
    "    It is assumed that the company only hires drivers that are from a city\n",
    "    where a bus goes to.  No need to verify that there is a route to the \n",
    "    home city based on the assumption given in the assignment.\n",
    "    \n",
    "    \"The company only hire drivers from cities where there is a route that \n",
    "    serves as its destination (destination ONLY, not departure city).\"\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, csv_path, dest_cities):\n",
    "        super().__init__(csv_path)\n",
    "        \n",
    "        self.column_names = ['driver_id', 'last_name', 'first_name', 'age', 'home_city',\n",
    "                            'home_state']\n",
    "        \n",
    "        self.dest_cities = dest_cities\n",
    "        \n",
    "        self.df = self.read_df()\n",
    "        \n",
    "    def read_df(self):\n",
    "        return self._read_df(file_type='drivers', names=self.column_names)\n",
    "    \n",
    "    def verify_df(self):\n",
    "        self._verify_attributes()\n",
    "        \n",
    "    def _verify_dest_city(self, city, state):\n",
    "        # Make sure the hometown is a destination city\n",
    "        if (city, state) in self.dest_cities:\n",
    "            return True\n",
    "        return False\n",
    "        \n",
    "    def _check_duplicates_by(self, column_name):\n",
    "        # adapted from: https://github.com/dask/dask/issues/2952\n",
    "        self.df = self.df.reset_index().drop_duplicates([column_name]).set_index(\"index\")\n",
    "    \n",
    "    def _verify_attributes(self):\n",
    "        '''Verifies basic attributes in the table. \n",
    "        \n",
    "        We verify that each of the attributes follows the datastructures we are placing on them,\n",
    "        and we may want to add functionality to drop any rows that are duplicates.  Note: we \n",
    "        must check if the dataframe is empty so that we avoid KeyErrors.\n",
    "        '''\n",
    "        \n",
    "        if self._is_empty(self.df):\n",
    "            return self.df\n",
    "        \n",
    "        # driver_id must be 5 characters and alphanumeric\n",
    "        self.df = self.df[self.df['driver_id'].apply(\n",
    "            lambda x: self._verify_id(x), meta=pd.Series([], dtype='str', name='x'))]\n",
    "\n",
    "        if self._is_empty(self.df):\n",
    "            return self.df\n",
    "        \n",
    "        # last_name, first_name are a max of 80 characters\n",
    "        self.df = self.df[self.df['last_name'].apply(\n",
    "            lambda x: self._verify_str_len(x, 1, 80), meta=pd.Series([], dtype='str', name='x'))]\n",
    "\n",
    "        if self._is_empty(self.df):\n",
    "            return self.df\n",
    "        \n",
    "        self.df = self.df[self.df['first_name'].apply(\n",
    "            lambda x: self._verify_str_len(x, 1, 80), meta=pd.Series([], dtype='str', name='x'))]\n",
    "        \n",
    "        if self._is_empty(self.df):\n",
    "            return self.df\n",
    "        \n",
    "        # age is up to 3 characters and is an integer from 16-100\n",
    "        self.df = self.df[self.df['age'].apply(\n",
    "            lambda x: self._verify_str_len(x, 2, 3) and self._verify_int_value(x, 16, 100),\n",
    "            meta=pd.Series([], dtype='str', name='x'))]\n",
    "        \n",
    "        if self._is_empty(self.df):\n",
    "            return self.df\n",
    "        \n",
    "        # home_city is a max of 80 characters\n",
    "        self.df = self.df[self.df['home_city'].apply(\n",
    "            lambda x: self._verify_str_len(x, 1, 80), meta=pd.Series([], dtype='str', name='x'))]\n",
    "\n",
    "        if self._is_empty(self.df):\n",
    "            return self.df\n",
    "        \n",
    "        # home_state must be 2 characters and valid state code\n",
    "        self.df = self.df[self.df['home_state'].apply(\n",
    "            lambda x: self._verify_str_len(x, 2, 2) and x in self.state_codes,\n",
    "            meta=pd.Series([], dtype='str', name='x'))]\n",
    "        \n",
    "        if self._is_empty(self.df):\n",
    "            return self.df\n",
    "        \n",
    "        # (home_city, home_state) must be a destination city\n",
    "        self.df = self.df[self.df[['home_city', 'home_state']].apply(\n",
    "            lambda x: self._verify_dest_city(*x), meta=pd.Series([], dtype='str', name='x'), axis=1)]\n",
    "        \n",
    "        if self._is_empty(self.df):\n",
    "            return self.df\n",
    "        \n",
    "        # remove duplicate IDs\n",
    "        self._check_duplicates_by('driver_id')\n",
    "        \n",
    "\n",
    "class RouteReader(DaskReader):\n",
    "    ''' Reads route csv files.\n",
    "    \n",
    "    Expected Columns\n",
    "    ----------------\n",
    "    Route number\n",
    "    Route name (left empty if not present)\n",
    "    Departure city name\n",
    "    Departure city code (standard US state code, 2 characters)\n",
    "    Destination city name\n",
    "    Destination city code\n",
    "    Route type code (0 for daily, 1 for weekdays only, 2for weekend only)\n",
    "    Departure time (hours)\n",
    "    Departure time (minutes)\n",
    "    Travel time (hours)\n",
    "    Travel time (minutes)\n",
    "    \n",
    "    I renamed them below so it is harder to accidentially call on the wrong\n",
    "    name (i.e. departure is now src)\n",
    "    \n",
    "    Helpful link: https://stackoverflow.com/questions/47125665/simple-dask-map-partitions-example\n",
    "    '''\n",
    "    def __init__(self, csv_path):\n",
    "        super().__init__(csv_path)\n",
    "        \n",
    "        self.column_names = ['route_id', 'route_name', 'src_city_name', 'src_state_code',\n",
    "                            'dest_city_name', 'dest_state_code', 'route_type', 'dep_time_hr',\n",
    "                             'dep_time_min', 'travel_time_hr', 'travel_time_min']\n",
    "        \n",
    "        self.df = self.read_df()\n",
    "        \n",
    "        self.user_time = 0\n",
    "        self.current_id = ''\n",
    "        \n",
    "    def read_df(self):\n",
    "        return self._read_df(file_type='routes', names=self.column_names)\n",
    "    \n",
    "    def verify_df(self):\n",
    "        self._verify_attributes()\n",
    "    \n",
    "    def _verify_time_less_than(self, hr, min_, max_minutes):\n",
    "        hr, min_ = int(hr), int(min_)\n",
    "        \n",
    "        if (hr*60) + min_ > max_minutes:\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def _check_duplicates_by(self, column_name):\n",
    "        # adapted from: https://github.com/dask/dask/issues/2952\n",
    "        self.df = self.df.reset_index().drop_duplicates([column_name]).set_index(\"index\")\n",
    "    \n",
    "    def _verify_attributes(self):\n",
    "        '''Verifies basic attributes in the table. \n",
    "        \n",
    "        We verify that each of the attributes follows the datastructures we are placing on them,\n",
    "        and we may want to add functionality to drop any rows that are duplicates.  Note: we \n",
    "        must check if the dataframe is empty so that we avoid KeyErrors.\n",
    "        \n",
    "        Note:  All of this culd be applied better but leaving for now for clarity.  Another thing\n",
    "        that we need to do here is remove duplicates of someone with the same ID.  Could just do \n",
    "        a groupby and remove all indices after the first occurance.  Looking into better ways to \n",
    "        handle the out of memory operations like the link I referenced at the beginning of the \n",
    "        '''\n",
    "#         https://docs.dask.org/en/latest/dataframe-api.html#dask.dataframe.DataFrame.dropna\n",
    "#             drop na for most attributes, but some are fine to be na\n",
    "        # drop nan rows for columns that must contain values\n",
    "        # causes issues for masking down the line...so I made my own helper function\n",
    "        \n",
    "        if self._is_empty(self.df):\n",
    "            return self.df\n",
    "        \n",
    "        # route_ID must be 5 characters and alphanumeric\n",
    "        # this could probably be improved, but I am still learning dask \n",
    "        self.df = self.df[self.df['route_id'].apply(\n",
    "            lambda x: self._verify_id(x), meta=pd.Series([], dtype='str', name='x'))]\n",
    "\n",
    "        if self._is_empty(self.df):\n",
    "            return self.df\n",
    "\n",
    "        # route_name is optional but a max of 80 characters\n",
    "        self.df = self.df[self.df['route_name'].apply(\n",
    "            lambda x: self._is_nan(x) or self._verify_str_len(x, 0, 80),\n",
    "            meta=pd.Series([], dtype='str', name='x'))]\n",
    "\n",
    "        if self._is_empty(self.df):\n",
    "                return self.df\n",
    "        \n",
    "        # src_city_name, dest_city_name are a max of 80 characters\n",
    "        self.df = self.df[self.df['src_city_name'].apply(\n",
    "            lambda x: self._verify_str_len(x, 1, 80), meta=pd.Series([], dtype='str', name='x'))]\n",
    "\n",
    "        if self._is_empty(self.df):\n",
    "            return self.df\n",
    "        \n",
    "        self.df = self.df[self.df['dest_city_name'].apply(\n",
    "            lambda x: self._verify_str_len(x, 1, 80), meta=pd.Series([], dtype='str', name='x'))]\n",
    "        \n",
    "        if self._is_empty(self.df):\n",
    "            return self.df\n",
    "            \n",
    "        # route_type is 1 character and can be the integers 0, 1, or 2\n",
    "        self.df = self.df[self.df['route_type'].apply(\n",
    "            lambda x: self._verify_str_len(x, 1, 1) and x in ['0', '1', '2'],\n",
    "            meta=pd.Series([], dtype='str', name='x'))]\n",
    "        \n",
    "        if self._is_empty(self.df):\n",
    "            return self.df\n",
    "        \n",
    "        # dep_time_hr is up to 2 characters and is an integer from 0-23\n",
    "        self.df = self.df[self.df['dep_time_hr'].apply(\n",
    "            lambda x: self._verify_str_len(x, 1, 2) and self._verify_int_value(x, 0, 23),\n",
    "            meta=pd.Series([], dtype='str', name='x'))]\n",
    "        \n",
    "        if self._is_empty(self.df):\n",
    "            return self.df\n",
    "        \n",
    "        # travel_time_hr is up to 2 characters and is an integer from 0-72\n",
    "        self.df = self.df[self.df['travel_time_hr'].apply(\n",
    "            lambda x: self._verify_str_len(x, 1, 2) and self._verify_int_value(x, 0, 72),\n",
    "            meta=pd.Series([], dtype='str', name='x'))]\n",
    "        \n",
    "        if self._is_empty(self.df):\n",
    "            return self.df\n",
    "        \n",
    "        # travel_time_min is up to 2 characters and is an integer from 0-59\n",
    "        self.df = self.df[self.df['travel_time_min'].apply(\n",
    "            lambda x: self._verify_str_len(x, 1, 2) and self._verify_int_value(x, 0, 59),\n",
    "            meta=pd.Series([], dtype='str', name='x'))]\n",
    "        \n",
    "        if self._is_empty(self.df):\n",
    "            return self.df\n",
    "        \n",
    "        # total travel time must not exceed 72 hrs\n",
    "        self.df = self.df[self.df[['travel_time_hr', 'travel_time_min']].apply(\n",
    "            lambda x: self._verify_time_less_than(*x, 72*60),\n",
    "            meta=pd.Series([], dtype='str', name='x'), axis=1)]\n",
    "        \n",
    "        if self._is_empty(self.df):\n",
    "            return self.df\n",
    "        \n",
    "        # src_state_code and dest_state_code must be 2 characters and valid state codes\n",
    "        self.df = self.df[self.df['src_state_code'].apply(\n",
    "            lambda x: self._verify_str_len(x, 2, 2) and x in self.state_codes,\n",
    "            meta=pd.Series([], dtype='str', name='x'))]\n",
    "        \n",
    "        if self._is_empty(self.df):\n",
    "            return self.df\n",
    "        \n",
    "        self.df = self.df[self.df['dest_state_code'].apply(\n",
    "            lambda x: self._verify_str_len(x, 2, 2) and x in self.state_codes,\n",
    "            meta=pd.Series([], dtype='str', name='x'))]\n",
    "        \n",
    "        # remove duplicate IDs\n",
    "        self._check_duplicates_by('route_id')\n",
    "        \n",
    "    def get_dest_city_names(self):\n",
    "        '''Returns a list with destination city names (unique with state)'''\n",
    "        cities_df = self.df[['dest_city_name', 'dest_state_code']]\n",
    "        cities_df = cities_df.reset_index().drop_duplicates(['dest_city_name', 'dest_state_code']).set_index(\"index\")\n",
    "        return list(cities_df.compute().itertuples(index=False, name=None))\n",
    "    \n",
    "    def to_csv(self):\n",
    "        save_root = './intermediate_csvs/routes/clean_routes-*.csv'\n",
    "        \n",
    "        # Save to csv (for each partition)\n",
    "        self.df.to_csv(save_root, header=None)\n",
    "        \n",
    "        # Concatenate csvs\n",
    "        concat_files = '/'.join(save_root.split('/')[:-1]) + '/*.csv'\n",
    "        concat_files = glob.glob(concat_files)\n",
    "        \n",
    "        # Create empty csv\n",
    "        dest = './processed_csvs/routes/routes.csv'\n",
    "        with open(dest, 'w') as empty_csv:\n",
    "            pass\n",
    "        \n",
    "        # if multiple files, concatenate\n",
    "        if len(concat_files) > 1:\n",
    "            self._concat_files(concat_files, dest)\n",
    "        else:\n",
    "            # copy full file over to the destination\n",
    "            copyfile(concat_files[0], dest)\n",
    "        \n",
    "        \n",
    "    ''' All functions below should be removed at a later time if we do not \n",
    "        need them.\n",
    "    '''\n",
    "    def grouper(self, column_name):\n",
    "        a = self.df.groupby(column_name)\n",
    "#         t = a.apply(self.checker, meta=pd.Series([], dtype='str', name='x'))\n",
    "        \n",
    "        t = a.apply(lambda x: self.test(x), meta=pd.Series([], dtype='str', name='x'))\n",
    "#         t = a.applymap(lambda x: self.test(x), meta=pd.Series([], dtype='str', name='x'))\n",
    "        return t\n",
    "    \n",
    "    def test(self, x):\n",
    "        self.user_time = 0\n",
    "        \n",
    "        t = x.applymap(lambda a: self.a)\n",
    "        return t\n",
    "    \n",
    "    def a(self, t):\n",
    "        print(t)\n",
    "    \n",
    "    def checker(self, x):\n",
    "        user_time = 0\n",
    "#         print(f'user time: {user_time} x: {x}')\n",
    "#         print(f'user time: {user_time} x: {x}\\n\\n')\n",
    "        return x.applymap(lambda row: self.row_check)\n",
    "#         user_time +=1\n",
    "        \n",
    "        \n",
    "    def row_check(self, row):\n",
    "        print(row)\n",
    "        return 0\n",
    "        \n",
    "    \n",
    "test_file = './test_csvs/routes/edited_Lin_Routes.csv'\n",
    "dr = RouteReader(test_file)\n",
    "# dr.df.head()\n",
    "dr.verify_df()\n",
    "dr.df.head()\n",
    "# print(dr.df.head())\n",
    "# dr.grouper('route_id').head()\n",
    "\n",
    "# v = dr._check_duplicates_by('route_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Dallas', 'TX')]\n",
      "      driver_id route_id day_of_week\n",
      "index                               \n",
      "15        100C5    A1355           M\n",
      "16        A3995    A1355           T\n",
      "17        100A5    A1355           W\n",
      "18        100B5    A1355           U\n",
      "19        100C5    A1356           F\n",
      "20        100A5    A1357           S\n",
      "21        100B5    A1358           s\n",
      "22        100A5    4B755           M\n",
      "23        B9335    4B756           T\n",
      "24        B9335    4B757           W\n",
      "25        100D5    4B758           U\n",
      "26        B9335    4B759           F\n",
      "27        100D5    4B760           S\n",
      "28        A3995    4B761           s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/clayharper/anaconda/envs/db_project_dask/lib/python3.7/site-packages/dask/dataframe/core.py:6194: UserWarning: Insufficient elements for `head`. 30 elements requested, only 14 elements available. Try passing larger `npartitions` to `head`.\n",
      "  warnings.warn(msg.format(n, len(r)))\n"
     ]
    }
   ],
   "source": [
    "# just for testing right now, will be a real main function later\n",
    "def main():\n",
    "    routes_file = './test_csvs/routes/edited_Lin_Routes.csv'\n",
    "    drivers_file = './test_csvs/drivers/Lin_Driver2.csv'\n",
    "    assignment_file = './test_csvs/assignments/Lin_Assignment2.csv'\n",
    "    \n",
    "    # First, read in routes so we can get the destination cities\n",
    "    routes_ddf = RouteReader(routes_file)\n",
    "    routes_ddf.verify_df()\n",
    "    routes_ddf.to_csv()\n",
    "    dest_cities = routes_ddf.get_dest_city_names()\n",
    "    print(dest_cities)\n",
    "    # Save cleaned data\n",
    "\n",
    "    # Read drivers and filter out (also considering that their hometown must be a destination)\n",
    "    driver_ddf = DriverReader(drivers_file, dest_cities=dest_cities)\n",
    "    driver_ddf.verify_df()\n",
    "    # Save cleaned data\n",
    "    \n",
    "    # Read assignments\n",
    "    assignment_ddf = AssignmentReader(assignment_file)\n",
    "    assignment_ddf.verify_df()\n",
    "    \n",
    "    print(assignment_ddf.df.head(30))\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "l = [('D', 'T')]\n",
    "print(('D', 'T') in l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dest_city_name</th>\n",
       "      <th>dest_state_code</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Waco</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dallas</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dest_city_name dest_state_code\n",
       "index                               \n",
       "0            Houston              TX\n",
       "1               Waco              TX\n",
       "2             Dallas              TX\n",
       "3               None              TX\n",
       "4               None            None"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file = './test_csvs/routes/edited_Lin_Routes.csv'\n",
    "dr = RouteReader(test_file)\n",
    "# dr.verify_df()\n",
    "dr.get_dest_city_names().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'dest_cities'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-63d40107b776>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./test_csvs/drivers/Lin_Driver2.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDriverReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# dr.df.head()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverify_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'dest_cities'"
     ]
    }
   ],
   "source": [
    "test_file = './test_csvs/drivers/Lin_Driver2.csv'\n",
    "dr = DriverReader(test_file)\n",
    "# dr.df.head()\n",
    "dr.verify_df()\n",
    "dr.df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible time overlap solution?\n",
    "\n",
    "https://stackoverflow.com/questions/57876479/efficient-way-to-compute-difference-of-all-rows-in-dask-dataframe\n",
    "https://stackoverflow.com/questions/60721290/how-to-apply-a-custom-function-to-groups-in-a-dask-dataframe-using-multiple-col\n",
    "https://docs.dask.org/en/latest/array.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.core.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100A</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100B</td>\n",
       "      <td>1</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100C</td>\n",
       "      <td>1</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100A</td>\n",
       "      <td>1</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100B</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100C</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100A</td>\n",
       "      <td>1</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200A</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100A</td>\n",
       "      <td>2</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100B</td>\n",
       "      <td>2</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100C</td>\n",
       "      <td>2</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100A</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100B</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100C</td>\n",
       "      <td>2</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100C</td>\n",
       "      <td>A13</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A399</td>\n",
       "      <td>A13</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100A</td>\n",
       "      <td>A13</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100B</td>\n",
       "      <td>A13</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100C</td>\n",
       "      <td>A13</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100A</td>\n",
       "      <td>A13</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>100B</td>\n",
       "      <td>A13</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>100A</td>\n",
       "      <td>4B7</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>B933</td>\n",
       "      <td>4B7</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>B933</td>\n",
       "      <td>4B7</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>100D</td>\n",
       "      <td>4B7</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>B933</td>\n",
       "      <td>4B7</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1  2\n",
       "0   100A    1  M\n",
       "1   100B    1  T\n",
       "2   100C    1  W\n",
       "3   100A    1  U\n",
       "4   100B    1  F\n",
       "5   100C    1  S\n",
       "6   100A    1  s\n",
       "7   200A    2  M\n",
       "8   100A    2  T\n",
       "9   100B    2  W\n",
       "10  100C    2  U\n",
       "11  100A    2  F\n",
       "12  100B    2  S\n",
       "13  100C    2  s\n",
       "14  100C  A13  M\n",
       "15  A399  A13  T\n",
       "16  100A  A13  W\n",
       "17  100B  A13  U\n",
       "18  100C  A13  F\n",
       "19  100A  A13  S\n",
       "20  100B  A13  s\n",
       "21  100A  4B7  M\n",
       "22  B933  4B7  T\n",
       "23  B933  4B7  W\n",
       "24  100D  4B7  U\n",
       "25  B933  4B7  F"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import dask\n",
    "\n",
    "assignment_csv_path = './test_csvs/assignments/Lin_Assignment.csv'\n",
    "\n",
    "df = dask.dataframe.read_csv(assignment_csv_path, dtype='str', header=None)\n",
    "# df = dd.read_csv(assignment_csv_path, dtype='str')\n",
    "print(type(df))\n",
    "df.head(26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
